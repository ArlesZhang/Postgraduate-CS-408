信息论基础 OVERVIEW ：信息论化繁为简的六大核心概念。

1.熵（Entropy）——不确定性的量度；
熵就是平均信息量，信息量 = “我对这个结果多惊讶”。
“熵是概率决定资源分配的核心”的核心本质！

2.相对熵（KL散度）——两个概率分布的“差距”；
KL散度是“以Q猜P”的代价。

3.微分熵（Differential Entropy）——连续变量的熵 连续变量的熵叫微分熵，本质是“密度函数的不确定性”。

4.数据压缩 vs. 博弈的对偶性 & 财富增长率（Kelly Criterion）——概率决定资源的分配。 
最佳压缩策略 = 最佳下注策略 
数据压缩 & 赌博 是信息论的一体两面！

5.信道容量定理（香农第二定理） 容量就是“无错误传输”的最高极限 香农告诉我们：不是信号越强越好，而是编码方式决定一切！

6.无噪声数据压缩理论 & 率失真理论
目标： 在没有任何信息丢失的前提下，把数据压到最小（前者）
目标： 如果你允许“差不多还原”，那压缩还能再狠一点！

相关阅读 ：《信息论与统计学习》和《深度学习的信息瓶颈解释》是在信息瓶颈（Information Bottleneck）理论领域被公认为“必读经典”，是我们可以接触 信息瓶颈原理（Information Bottleneck），这是现代深度学习和信息论 结合的核心桥梁 。
